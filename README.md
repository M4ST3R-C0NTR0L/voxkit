<div align="center">

# ğŸ™ï¸ VoxKit

**The open-source voice agent framework.**  
Build AI-powered voice agents in ~20 lines of TypeScript.

[![npm version](https://img.shields.io/npm/v/voxkit.svg?style=flat-square)](https://www.npmjs.com/package/voxkit)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.0+-blue?style=flat-square&logo=typescript)](https://www.typescriptlang.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green?style=flat-square)](LICENSE)
[![Tests](https://img.shields.io/badge/tests-passing-brightgreen?style=flat-square)](#tests)
[![Node](https://img.shields.io/badge/node-%3E%3D18-brightgreen?style=flat-square&logo=node.js)](https://nodejs.org/)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-orange?style=flat-square)](CONTRIBUTING.md)

[Quick Start](#quick-start) Â· [Examples](#examples) Â· [API Reference](#api-reference) Â· [Providers](#providers) Â· [Plugins](#plugins) Â· [Contributing](#contributing)

</div>

---

## What is VoxKit?

VoxKit is a TypeScript-first framework for building production-ready AI voice agents. It handles all the hard parts â€” WebSocket audio streaming, speech-to-text, text-to-speech, conversation state, lead extraction, and reconnection â€” so you can focus on what your agent *does*.

### Why VoxKit?

| Without VoxKit | With VoxKit |
|---|---|
| âŒ Wire up WebSocket servers manually | âœ… `agent.listen(3000)` |
| âŒ Handle audio buffering & VAD yourself | âœ… AudioPipeline handles it |
| âŒ Build conversation context from scratch | âœ… ConversationManager built-in |
| âŒ Write regex for lead extraction | âœ… LeadExtractor auto-runs |
| âŒ Implement reconnection logic | âœ… Automatic with exponential backoff |
| âŒ Learn 4 different provider APIs | âœ… One unified interface |

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         VoxKit Framework                        â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                       VoxAgent                          â”‚   â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚   â”‚   WebSocket â”‚  â”‚ Conversation â”‚  â”‚    Lead      â”‚  â”‚   â”‚
â”‚  â”‚   â”‚   Server    â”‚  â”‚   Manager   â”‚  â”‚  Extractor   â”‚  â”‚   â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚          â”‚                â”‚                  â”‚           â”‚   â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”    â”‚   â”‚
â”‚  â”‚   â”‚              Audio Pipeline                     â”‚    â”‚   â”‚
â”‚  â”‚   â”‚   [Buffer] â†’ [VAD] â†’ [Format Conversion]       â”‚    â”‚   â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                             â”‚                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    Provider Layer                         â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚  OpenAI   â”‚  â”‚  xAI  â”‚  â”‚ Anthropic â”‚  â”‚ Deepgram â”‚  â”‚  â”‚
â”‚  â”‚  â”‚ Realtime  â”‚  â”‚  Grok  â”‚  â”‚  Claude   â”‚  â”‚  Nova-2  â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    Plugin System                          â”‚  â”‚
â”‚  â”‚  [TranscriptLogger] [LeadWebhook] [Slack] [Metrics] ...   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Client (Browser / Twilio / SIP)
    â”‚
    â”‚  WebSocket (ws://)
    â”‚  Binary audio frames (PCM16)
    â–¼
VoxKit Server
```

---

## Quick Start

### Installation

```bash
npm install voxkit
# or
yarn add voxkit
# or
pnpm add voxkit
```

### Your first voice agent (20 lines)

```typescript
import { VoxAgent, OpenAIProvider } from 'voxkit'

const agent = new VoxAgent({
  provider: new OpenAIProvider({ model: 'gpt-4o' }),
  voice: 'alloy',
  systemPrompt: 'You are a helpful assistant for a real estate company.',
  onTranscript: (text) => console.log('User said:', text),
  onLead:       (data) => saveLead(data),
})

agent.listen(3000)
```

That's it. Your agent is now:
- Accepting WebSocket audio connections on port 3000
- Transcribing speech with Whisper
- Generating responses with GPT-4o
- Speaking back with neural TTS
- Automatically extracting name, email, and phone from the conversation

---

## CLI

Scaffold, develop, and deploy with the `voxkit` CLI.

```bash
# Create a new agent from a template
npx voxkit init my-agent
npx voxkit init my-agent --template real-estate --provider openai
npx voxkit init my-agent --template customer-support --provider anthropic

# Run with hot reload (watches src/ for changes)
npx voxkit dev
npx voxkit dev --port 8080

# Deployment guide
npx voxkit deploy
npx voxkit deploy --platform railway
npx voxkit deploy --platform render
npx voxkit deploy --platform fly
npx voxkit deploy --platform docker
```

Available templates: `basic` Â· `real-estate` Â· `customer-support`

---

## Examples

| Example | What it demonstrates |
|---|---|
| [`examples/basic-agent`](examples/basic-agent) | Minimal setup, one provider |
| [`examples/real-estate-agent`](examples/real-estate-agent) | Lead capture, CRM webhook, Slack notifications |
| [`examples/customer-support`](examples/customer-support) | Ticket creation, QA transcripts, support metrics |

```bash
cd examples/real-estate-agent
npm install
cp .env.example .env   # add your OpenAI key
npm run dev
```

---

## API Reference

### `new VoxAgent(config)`

The main class. Creates a fully configured voice agent.

```typescript
const agent = new VoxAgent({
  // Required
  provider: new OpenAIProvider({ model: 'gpt-4o' }),

  // Voice & persona
  voice: 'alloy',              // 'alloy' | 'echo' | 'fable' | 'onyx' | 'nova' | 'shimmer'
  systemPrompt: 'You areâ€¦',   // LLM system prompt

  // Features
  enableLeadExtraction: true,         // Auto-extract name/email/phone (default: true)
  maxConversationDuration: 3600,      // Max call duration in seconds (default: 3600)
  silenceTimeoutMs: 30_000,           // End call after N ms of silence (default: 30000)

  // Audio
  audioConfig: {
    sampleRate: 24000,    // Default: 24000
    channels: 1,          // Default: 1 (mono)
    format: 'pcm16',      // 'pcm16' | 'g711_ulaw' | 'g711_alaw'
  },

  // Event callbacks
  onTranscript: (text, segment)        => { /* user spoke */ },
  onResponse:   (text, response)       => { /* agent replied */ },
  onLead:       (lead, conversation)   => { /* contact info captured */ },
  onError:      (error, context)       => { /* something went wrong */ },
  onConnect:    (connected)            => { /* connection state changed */ },
})
```

### Instance methods

```typescript
// Start the WebSocket server (most common usage)
await agent.listen(3000)
await agent.listen(3000, '0.0.0.0')

// Stop gracefully (drains connections, extracts final lead)
await agent.stop()

// Connect/disconnect the AI provider directly (no WS server)
await agent.connect()
await agent.disconnect()

// Send text without audio (useful for testing or text-only clients)
await agent.sendText('Hello, can you help me?')

// Plugin system
agent.use(new TranscriptLoggerPlugin())

// Retrieve state
agent.getTranscript()          // Full conversation as plain text
agent.exportConversation()     // Full conversation as JSON
agent.getCurrentLead()         // Best lead captured so far
agent.conversation             // ConversationState object
agent.isConnected              // boolean
```

### Events

```typescript
agent.on('transcript',      (text, segment)      => {})
agent.on('response',        (text, response)     => {})
agent.on('lead',            (lead, conversation) => {})
agent.on('error',           (error, context)     => {})
agent.on('connect',         (connected)          => {})
agent.on('disconnect',      ()                   => {})
agent.on('silenceTimeout',  (conversation)       => {})
agent.on('clientConnect',   (wsClient)           => {})
agent.on('clientDisconnect',(wsClient)           => {})
```

---

## Providers

All providers implement the `AIProvider` interface. Swap them with zero changes to your agent code.

### OpenAI (Realtime API) â€” best for voice

```typescript
import { OpenAIProvider } from 'voxkit'

new OpenAIProvider({
  apiKey: process.env.OPENAI_API_KEY,   // or set OPENAI_API_KEY env var
  model:  'gpt-4o-realtime-preview-2024-12-17',
  voice:  'alloy',
  temperature: 0.8,
  maxResponseOutputTokens: 4096,
})
```

Supported voices: `alloy` `echo` `fable` `onyx` `nova` `shimmer` `ash` `ballad` `coral` `sage` `verse`

### xAI / Grok

```typescript
import { XAIProvider } from 'voxkit/providers'

new XAIProvider({
  apiKey: process.env.XAI_API_KEY,
  model: 'grok-2-1212',
  streaming: true,
})
```

### Anthropic / Claude

```typescript
import { AnthropicProvider } from 'voxkit/providers'

new AnthropicProvider({
  apiKey: process.env.ANTHROPIC_API_KEY,
  model: 'claude-3-5-sonnet-20241022',
  maxTokens: 4096,
  streaming: true,
})
```

### Deepgram (STT-only)

```typescript
import { DeepgramProvider } from 'voxkit/providers'

new DeepgramProvider({
  apiKey: process.env.DEEPGRAM_API_KEY,
  model: 'nova-2',
  language: 'en-US',
  smartFormat: true,
  punctuate: true,
})
```

### Build your own provider

```typescript
import type { AIProvider, Voice, TranscriptSegment, ProviderResponse } from 'voxkit'

class MyCustomProvider implements AIProvider {
  name = 'my-provider'

  async initialize(): Promise<void> { /* set up */ }
  async connect():    Promise<void> { /* open connection */ }
  async disconnect(): Promise<void> { /* close connection */ }

  async sendAudio(audio: Uint8Array): Promise<void> { /* stream audio */ }
  async sendText(text: string):       Promise<void> { /* send text */ }

  onResponse(cb: (r: ProviderResponse) => void):   void { /* register */ }
  onTranscript(cb: (s: TranscriptSegment) => void): void { /* register */ }
  onError(cb: (e: Error) => void):                 void { /* register */ }

  getSupportedVoices(): Voice[] { return ['alloy'] }
  setVoice(voice: Voice): void  { /* update */ }
}

// Use it just like any built-in provider:
const agent = new VoxAgent({ provider: new MyCustomProvider() })
```

---

## Plugins

Plugins extend VoxAgent's capabilities via lifecycle hooks.

### Built-in plugins

```typescript
import {
  TranscriptLoggerPlugin,
  LeadWebhookPlugin,
  SlackNotifierPlugin,
  MetricsPlugin
} from 'voxkit'

// Save full transcripts to disk (JSONL)
agent.use(new TranscriptLoggerPlugin({
  filePath: './transcripts.jsonl',
  timestamps: true,
  tag: '[call]'
}))

// POST leads to any HTTP endpoint
agent.use(new LeadWebhookPlugin({
  url:     'https://your-crm.com/api/leads',
  secret:  process.env.CRM_SECRET,
  retries: 3
}))

// Ping Slack on every captured lead
agent.use(new SlackNotifierPlugin({
  webhookUrl: process.env.SLACK_WEBHOOK_URL,
  emoji: ':telephone_receiver:'
}))

// Track session metrics
const metrics = new MetricsPlugin({ printSummary: true })
agent.use(metrics)
// Later: metrics.getMetrics() â†’ { turnCount, durationMs, leadCaptured, ... }
```

### Write your own plugin

```typescript
import type { VoxKitPlugin, VoxAgent, ConversationMessage, LeadInfo } from 'voxkit'

class MyCRMPlugin implements VoxKitPlugin {
  name = 'my-crm'

  initialize(agent: VoxAgent): void {
    console.log('CRM plugin ready')
  }

  onMessage(message: ConversationMessage): void {
    // runs on every conversation turn
  }

  onLead(lead: LeadInfo): void {
    // runs when contact info is captured
    myCRM.createContact(lead)
  }

  async destroy(): Promise<void> {
    // cleanup on agent.stop()
  }
}

agent.use(new MyCRMPlugin())
```

---

## Lead Extraction

VoxKit automatically extracts contact information from natural speech â€” no regex work required.

```typescript
// Automatically detected patterns:
// "My name is Sarah Johnson"     â†’ { name: 'Sarah Johnson' }
// "Email me at hello@example.com" â†’ { email: 'hello@example.com' }
// "Call me at 415-555-1234"       â†’ { phone: '+14155551234' }
// "I work at Acme Corp"           â†’ { company: 'Acme Corp' }

agent.on('lead', (lead) => {
  console.log(lead)
  // {
  //   name:    'Sarah Johnson',
  //   email:   'sarah@example.com',
  //   phone:   '+14155551234',
  //   company: 'Acme Corp',
  //   confidence: { name: 0.85, email: 1.0, phone: 1.0 }
  // }
})
```

Lead extraction is additive â€” it builds up across multiple turns and fires `onLead` as new info arrives. You can also call `agent.getCurrentLead()` at any time.

---

## Types

VoxKit is fully typed. Key interfaces:

```typescript
interface LeadInfo {
  name?:    string
  email?:   string
  phone?:   string
  company?: string
  notes?:   string
  confidence: { name?: number; email?: number; phone?: number }
}

interface ConversationState {
  id:             string
  messages:       ConversationMessage[]
  isActive:       boolean
  startedAt:      number
  lastActivityAt: number
  metadata?:      Record<string, unknown>
}

interface ConversationMessage {
  role:      'system' | 'user' | 'assistant' | 'function'
  content:   string
  timestamp?: number
  metadata?:  Record<string, unknown>
}

interface TranscriptSegment {
  id:         string
  text:       string
  isFinal:    boolean
  timestamp:  number
  speaker?:   string
  confidence?: number
}
```

---

## Environment Variables

| Variable | Required | Description |
|---|---|---|
| `OPENAI_API_KEY` | For OpenAI provider | Your OpenAI API key |
| `XAI_API_KEY` | For xAI provider | Your xAI API key |
| `ANTHROPIC_API_KEY` | For Anthropic provider | Your Anthropic API key |
| `DEEPGRAM_API_KEY` | For Deepgram provider | Your Deepgram API key |
| `PORT` | No | Server port (default: 3000) |
| `VOXKIT_DEBUG` | No | Enable debug logging (`true`/`false`) |

---

## Tests

```bash
# Run all tests
npm test

# Watch mode
npm test -- --watch

# Coverage report
npm run test:coverage
```

VoxKit uses [Vitest](https://vitest.dev/) and targets >90% coverage of core modules.

---

## Deployment

### Railway (recommended)

```bash
npm install -g @railway/cli
railway login
railway init
railway variables set OPENAI_API_KEY=sk-...
railway up
```

### Docker

```dockerfile
FROM node:20-alpine
WORKDIR /app
COPY package*.json ./
RUN npm ci
COPY . .
RUN npm run build
EXPOSE 3000
CMD ["node", "dist/agent.js"]
```

```bash
docker build -t my-voice-agent .
docker run -p 3000:3000 -e OPENAI_API_KEY=sk-... my-voice-agent
```

### Render / Fly.io

```bash
npx voxkit deploy --platform render
npx voxkit deploy --platform fly
```

---

## Project Structure

```
voxkit/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts                  # Main exports
â”‚   â”œâ”€â”€ voxagent.ts               # VoxAgent class
â”‚   â”œâ”€â”€ types.ts                  # All TypeScript types
â”‚   â”œâ”€â”€ logger.ts                 # Internal logger
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ audio-pipeline.ts     # Audio streaming & buffering
â”‚   â”‚   â”œâ”€â”€ conversation-manager.ts # Conversation state
â”‚   â”‚   â”œâ”€â”€ lead-extractor.ts     # Contact info extraction
â”‚   â”‚   â””â”€â”€ websocket-server.ts   # WS server with heartbeats
â”‚   â”œâ”€â”€ providers/
â”‚   â”‚   â”œâ”€â”€ openai.ts             # OpenAI Realtime API
â”‚   â”‚   â”œâ”€â”€ xai.ts                # xAI / Grok
â”‚   â”‚   â”œâ”€â”€ anthropic.ts          # Anthropic Claude
â”‚   â”‚   â”œâ”€â”€ deepgram.ts           # Deepgram STT
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”œâ”€â”€ plugins/
â”‚   â”‚   â”œâ”€â”€ transcript-logger.ts  # JSONL transcript logging
â”‚   â”‚   â”œâ”€â”€ lead-webhook.ts       # HTTP lead delivery
â”‚   â”‚   â”œâ”€â”€ slack-notifier.ts     # Slack lead notifications
â”‚   â”‚   â”œâ”€â”€ metrics.ts            # Session metrics
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â””â”€â”€ cli/
â”‚       â”œâ”€â”€ index.ts              # CLI entry point
â”‚       â””â”€â”€ commands/
â”‚           â”œâ”€â”€ init.ts           # voxkit init
â”‚           â”œâ”€â”€ dev.ts            # voxkit dev
â”‚           â”œâ”€â”€ deploy.ts         # voxkit deploy
â”‚           â””â”€â”€ version.ts        # voxkit version
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ audio-pipeline.test.ts
â”‚   â”‚   â”œâ”€â”€ conversation-manager.test.ts
â”‚   â”‚   â””â”€â”€ lead-extractor.test.ts
â”‚   â”œâ”€â”€ plugins/
â”‚   â”‚   â”œâ”€â”€ metrics.test.ts
â”‚   â”‚   â””â”€â”€ transcript-logger.test.ts
â”‚   â””â”€â”€ providers/
â”‚       â””â”€â”€ lead-extractor-edge-cases.test.ts
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ basic-agent/              # Minimal example
â”‚   â”œâ”€â”€ real-estate-agent/        # Lead capture + CRM
â”‚   â””â”€â”€ customer-support/         # Ticketing + QA
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â”œâ”€â”€ tsup.config.ts
â”œâ”€â”€ vitest.config.ts
â””â”€â”€ README.md
```

---

## Contributing

Contributions are welcome! Here's how to get started:

```bash
git clone https://github.com/voxkit/voxkit.git
cd voxkit
npm install
npm run dev          # watch mode build
npm test             # run tests
```

**Good first issues:**
- Add a new provider (ElevenLabs, Twilio, Groqâ€¦)
- Add a new plugin (HubSpot, Salesforce, Discordâ€¦)
- Improve VAD accuracy in AudioPipeline
- Add WebRTC support

Please read [CONTRIBUTING.md](CONTRIBUTING.md) before submitting a PR.

---

## Roadmap

- [ ] WebRTC support (browser â†” agent directly)
- [ ] Twilio Media Streams integration
- [ ] ElevenLabs TTS provider
- [ ] Groq Whisper STT provider
- [ ] Multi-language support
- [ ] Call recording & playback
- [ ] Built-in phone number provisioning
- [ ] Dashboard UI for monitoring live calls
- [ ] Multi-agent orchestration

---

## License

MIT Â© [VoxKit](https://github.com/voxkit/voxkit)

---

<div align="center">
  <strong>Built with â¤ï¸ for the open-source community.</strong><br/>
  <sub>Star â­ this repo if VoxKit saved you time!</sub>
</div>
